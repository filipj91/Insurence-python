# -*- coding: utf-8 -*-
"""Cost insurence Vol2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aWVqA3-RrJ-my7GJqgMEwegrQcIhLRq7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV
import warnings
import gdown

warnings.filterwarnings("ignore")

# Google Drive file ID
file_id = "1-9hXY8s5kDU4JEmQiehvLV_h8nc3MYy2"  # Zmień na ID pliku
url = f"https://drive.google.com/uc?id={file_id}"

# Pobieranie danych z Google Drive
output = "insurance.csv"
gdown.download(url, output, quiet=False)

# Wczytanie danych
df = pd.read_csv(output)

# Podstawowe informacje o danych
print(df.head())
print(df.shape)
print(df.isnull().sum())
print(df.describe())
print(df.info())

# Wizualizacje
sns.set()

plt.figure(figsize=(6, 6))
sns.histplot(df['age'], kde=True)
plt.title('Age Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.countplot(x='sex', data=df)
plt.title('Sex Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.histplot(df['bmi'], kde=True)
plt.title('BMI Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.countplot(x='children', data=df)
plt.title('Children Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.countplot(x='smoker', data=df)
plt.title('Smoker Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.countplot(x='region', data=df)
plt.title('Region Distribution')
plt.show()

plt.figure(figsize=(6, 6))
sns.histplot(df['charges'], kde=True)
plt.title('Charges Distribution')
plt.show()

# Kodowanie zmiennych kategorycznych
df.replace({'sex': {'male': 0, 'female': 1}}, inplace=True)
df.replace({'smoker': {'yes': 0, 'no': 1}}, inplace=True)
df.replace({'region': {'southeast': 0, 'southwest': 1, 'northeast': 2, 'northwest': 3}}, inplace=True)

# Przygotowanie danych
X = df.drop(columns='charges', axis=1)
Y = df['charges']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Skalowanie danych
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 1. Regresja Liniowa
linear_regressor = LinearRegression()
linear_regressor.fit(X_train_scaled, Y_train)

training_data_prediction_lr = linear_regressor.predict(X_train_scaled)
r2_train_lr = metrics.r2_score(Y_train, training_data_prediction_lr)
print('R squared for training data (Linear Regression): ', r2_train_lr)

test_data_prediction_lr = linear_regressor.predict(X_test_scaled)
r2_test_lr = metrics.r2_score(Y_test, test_data_prediction_lr)
print('R squared for test data (Linear Regression): ', r2_test_lr)

# 2. Random Forest Regressor
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
rf_regressor.fit(X_train_scaled, Y_train)

training_data_prediction_rf = rf_regressor.predict(X_train_scaled)
r2_train_rf = metrics.r2_score(Y_train, training_data_prediction_rf)
print('R squared for training data (Random Forest): ', r2_train_rf)

test_data_prediction_rf = rf_regressor.predict(X_test_scaled)
r2_test_rf = metrics.r2_score(Y_test, test_data_prediction_rf)
print('R squared for test data (Random Forest): ', r2_test_rf)

# 3. GridSearchCV dla tuningu hiperparametrów Random Forest
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train_scaled, Y_train)

print("Best parameters for Random Forest:", grid_search.best_params_)

best_rf_regressor = grid_search.best_estimator_

training_data_prediction_rf_best = best_rf_regressor.predict(X_train_scaled)
r2_train_rf_best = metrics.r2_score(Y_train, training_data_prediction_rf_best)
print('R squared for training data (Tuned Random Forest): ', r2_train_rf_best)

test_data_prediction_rf_best = best_rf_regressor.predict(X_test_scaled)
r2_test_rf_best = metrics.r2_score(Y_test, test_data_prediction_rf_best)
print('R squared for test data (Tuned Random Forest): ', r2_test_rf_best)

# 4. Predykcja dla nowych danych wejściowych
input_data = (31, 1, 25.74, 0, 1, 0)
input_data_as_numpy_array = np.asarray(input_data).reshape(1, -1)
input_data_scaled = scaler.transform(input_data_as_numpy_array)

# Predykcja dla regresji liniowej
prediction_lr = linear_regressor.predict(input_data_scaled)
print('Predicted insurance cost using Linear Regression: USD', prediction_lr[0])

# Predykcja dla Random Forest
prediction_rf = rf_regressor.predict(input_data_scaled)
print('Predicted insurance cost using Random Forest: USD', prediction_rf[0])

# Predykcja dla najlepszego modelu Random Forest
prediction_rf_best = best_rf_regressor.predict(input_data_scaled)
print('Predicted insurance cost using Tuned Random Forest: USD', prediction_rf_best[0])